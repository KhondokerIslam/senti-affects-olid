{"cells":[{"cell_type":"markdown","metadata":{"id":"jeLzOfs_JnkR"},"source":["# Imports"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"zIzA4RbtJqes"},"outputs":[],"source":["import os\n","import pandas as pd\n","from sklearn.metrics import f1_score\n","from sklearn.linear_model import LogisticRegression\n","from sklearn.svm import SVC\n","from sklearn.svm import LinearSVC\n","from sklearn.pipeline import make_pipeline, Pipeline\n","from sklearn.metrics import classification_report\n","from sklearn.pipeline import FeatureUnion\n","from sklearn import model_selection, preprocessing, linear_model, naive_bayes, metrics, svm\n","from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n","from sklearn.feature_extraction.text import TfidfTransformer\n","import matplotlib.pyplot as plt\n","from sklearn.metrics import precision_recall_fscore_support\n","from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score\n","import pandas as pd\n","from sklearn.model_selection import train_test_split\n","from sklearn.model_selection import cross_val_score, KFold\n","from scipy.sparse import hstack\n","from sklearn.metrics import confusion_matrix\n","import numpy as np\n","import seaborn as sns\n","\n","from sklearn.metrics import confusion_matrix"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":393},"executionInfo":{"elapsed":4286,"status":"error","timestamp":1729850920262,"user":{"displayName":"K.I. Islam","userId":"09685597978258818855"},"user_tz":-120},"id":"GyzCEFlnseU9","outputId":"685f9d22-92bb-4df8-cc66-e73bbb7d18f8"},"outputs":[{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/sklearn/feature_extraction/text.py:521: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n","  warnings.warn(\n"]},{"ename":"KeyboardInterrupt","evalue":"","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-2-e26fd46211f8>\u001b[0m in \u001b[0;36m<cell line: 156>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    165\u001b[0m     \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Label'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Label'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"NOT\"\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    166\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 167\u001b[0;31m   \u001b[0mfeature_based\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdf_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgram\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"word\"\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m<ipython-input-2-e26fd46211f8>\u001b[0m in \u001b[0;36mfeature_based\u001b[0;34m(train, test, c, x1, y1, gram)\u001b[0m\n\u001b[1;32m    143\u001b[0m     \u001b[0mlinear\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLinearSVC\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mC\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpenalty\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'l2'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'squared_hinge'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#squared_\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    144\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 145\u001b[0;31m     \u001b[0mlinear\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrainLabel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    146\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    147\u001b[0m     \u001b[0mpred_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlinear\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxtest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/base.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1471\u001b[0m                 )\n\u001b[1;32m   1472\u001b[0m             ):\n\u001b[0;32m-> 1473\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfit_method\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1474\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1475\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/svm/_classes.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    315\u001b[0m         )\n\u001b[1;32m    316\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 317\u001b[0;31m         self.coef_, self.intercept_, n_iter_ = _fit_liblinear(\n\u001b[0m\u001b[1;32m    318\u001b[0m             \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    319\u001b[0m             \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/svm/_base.py\u001b[0m in \u001b[0;36m_fit_liblinear\u001b[0;34m(X, y, C, fit_intercept, intercept_scaling, class_weight, penalty, dual, verbose, max_iter, tol, random_state, multi_class, loss, epsilon, sample_weight)\u001b[0m\n\u001b[1;32m   1213\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1214\u001b[0m     \u001b[0msolver_type\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_get_liblinear_solver_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmulti_class\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpenalty\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdual\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1215\u001b[0;31m     raw_coef_, n_iter_ = liblinear.train_wrap(\n\u001b[0m\u001b[1;32m   1216\u001b[0m         \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1217\u001b[0m         \u001b[0my_ind\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}],"source":["# def RecallPrecisionFScore(y_test, pred):\n","#     arr = confusion_matrix(y_test, pred)\n","\n","#     # Extracting the elements from the confusion matrix\n","#     tn, fp, fn, tp = arr.ravel()\n","\n","#     # Calculating precision, recall, and F1 score\n","#     precision = tp / (tp + fp) if (tp + fp) != 0 else 0\n","#     recall = tp / (tp + fn) if (tp + fn) != 0 else 0\n","#     f1 = (2 * precision * recall) / (precision + recall) if (precision + recall) != 0 else 0\n","\n","#     # Formatting and printing the results\n","#     precision, recall, f1 = round(precision * 100, 2), round(recall * 100, 2), round(f1 * 100, 2)\n","#     print(\"Precision:\", precision)\n","#     print(\"Recall:\", recall)\n","#     print(\"F1 score:\", f1)\n","\n","#     return precision, recall, f1\n","\n","\n","# def feature_based_combination(train, test, c, x1, y1, x2, y2 ):\n","\n","#   emotions = [ \"Love\", \"Joy\", \"Surprise\", \"Anger\", \"Sadness\", \"Fear\"]\n","\n","#   fin = []\n","\n","#   temp = []\n","\n","#   f1_dic = dict()\n","\n","#   scores = []\n","#   test_targ_id = []\n","#   test_targ_id = test[\"ID\"].tolist()\n","\n","#   # temp.append( test_[\"ID\"].tolist() )\n","\n","#   for emotion in emotions:\n","#     trainData = train['Data']\n","#     trainLabel = train[emotion]\n","#     testData = test['Data']\n","#     testLabel = test[emotion].tolist()\n","\n","\n","#     # tfidf_vect_ngram = TfidfVectorizer(analyzer='char', ngram_range=(7,7), max_features=300000, max_df = 0.99)\n","#     word_tfidf_vect_ngram = TfidfVectorizer(analyzer=\"word\", ngram_range=(x1,y1), tokenizer=lambda x: x.split())\n","\n","#     word_fit = word_tfidf_vect_ngram.fit(trainData)\n","#     feature_names_words = word_tfidf_vect_ngram.get_feature_names()\n","#     xtrain_words = word_tfidf_vect_ngram.transform(trainData)\n","#     xtest_words = word_tfidf_vect_ngram.transform(testData)\n","\n","\n","#     char_tfidf_vect_ngram = TfidfVectorizer(analyzer=\"char\", ngram_range=(x2,y2), tokenizer=lambda x: x.split())\n","\n","#     char_tfidf_vect_ngram.fit(trainData)\n","#     feature_names_char = char_tfidf_vect_ngram.get_feature_names()\n","#     xtrain_char = char_tfidf_vect_ngram.transform(trainData)\n","#     xtest_char = char_tfidf_vect_ngram.transform(testData)\n","\n","#     tfidf_matrix_word_char_train =  hstack((xtrain_words, xtrain_char))\n","#     tfidf_matrix_word_char_test =  hstack((xtest_words, xtest_char))\n","\n","\n","#     linear = LinearSVC(C = c, penalty='l2', loss = 'squared_hinge') #squared_\n","\n","#     linear.fit(tfidf_matrix_word_char_train, trainLabel)\n","\n","#     pred_test = linear.predict(tfidf_matrix_word_char_test)\n","\n","\n","#     oneCount = 0\n","#     for i in range(len(pred_test)):\n","#       if(pred_test[i] == testLabel[i] and testLabel[i] == 1):\n","#         oneCount += 1\n","\n","#     # print(\"oneCount: \",oneCount)\n","\n","#     pred_tem_test = pred_test.tolist()\n","#     # temp.append( pred_tem_test )\n","#     # temp.append( testLabel )\n","\n","\n","#     arr = confusion_matrix(testLabel, pred_tem_test)\n","#     # print(arr)\n","\n","#     f1 = f1_score( testLabel, pred_tem_test )\n","\n","#     scores.append( round(f1 * 100, 2) )\n","\n","#     f1_dic[emotion] = round(f1 * 100, 2)\n","\n","#   print(f1_dic)\n","#   #print(scores)\n","#   print( \"Macro Average F1-score: \", float('{0:.2f}'.format(sum(scores)/len(scores))) )\n","\n","\n","def feature_based(train, test, c, x1, y1, gram):\n","\n","    scores = []\n","\n","\n","    trainData = train['Data']\n","    trainLabel = train['Label']\n","    testData = test['Data']\n","    testLabel = test['Label']\n","\n","\n","\n","    # tfidf_vect_ngram = TfidfVectorizer(analyzer='char', ngram_range=(7,7), max_features=300000, max_df = 0.99)\n","    tfidf_vect_ngram = TfidfVectorizer(analyzer=gram, ngram_range=(x1,y1), tokenizer=lambda x: x.split())\n","\n","    tfidf_vect_ngram.fit(trainData)\n","    #feature_names = tfidf_vect_ngram.get_feature_names()\n","    xtrain =  tfidf_vect_ngram.transform(trainData)\n","    xtest =  tfidf_vect_ngram.transform(testData)\n","\n","\n","    linear = LinearSVC(C = c, penalty='l2', loss = 'squared_hinge') #squared_\n","\n","    linear.fit(xtrain, trainLabel)\n","\n","    pred_test = linear.predict(xtest)\n","\n","    # print(pred_test)\n","\n","    f1 = round(f1_score(testLabel, pred_test) * 100, 2)\n","    print(\"F1: \", f1)\n","\n","\n","\n","if __name__ == '__main__':\n","\n","  # path_parent = os.path.dirname( os.getcwd() )\n","  # os.chdir( path_parent )\n","  df_train = pd.read_csv( \"/content/drive/MyDrive/1a/Learning From Data/Final Project/data/train.tsv\", sep=\"\\t\", names = ['Data', 'Label'] )\n","  df_val =  pd.read_csv( \"/content/drive/MyDrive/1a/Learning From Data/Final Project/data/dev.tsv\", sep=\"\\t\", names = ['Data', 'Label'] )\n","  df_test = pd.read_csv( \"/content/drive/MyDrive/1a/Learning From Data/Final Project/data/test.tsv\", sep=\"\\t\", names = ['Data', 'Label'] )\n","\n","  for df in [df_train, df_val, df_test]:\n","    df['Label'] = df['Label'].apply(lambda x: 0 if x == \"NOT\" else 1 )\n","\n","  feature_based(df_train, df_test, c = 10, x1 = 1, y1 = 1, gram = \"word\" )"]},{"cell_type":"markdown","metadata":{"id":"T_iEX48GF5Rf"},"source":["# Word N-Gram *Tuning*"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":444623,"status":"ok","timestamp":1729850377946,"user":{"displayName":"K.I. Islam","userId":"09685597978258818855"},"user_tz":-120},"id":"KShvl68Y70oX","outputId":"4aa78a66-0368-4243-b58d-c2b0424299c3"},"outputs":[{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/sklearn/feature_extraction/text.py:521: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/feature_extraction/text.py:521: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n","  warnings.warn(\n"]},{"name":"stdout","output_type":"stream","text":["word (1-1)\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/feature_extraction/text.py:521: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n","  warnings.warn(\n"]},{"name":"stdout","output_type":"stream","text":["word (1-1)\n","word (1-1)\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/sklearn/feature_extraction/text.py:521: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n","  warnings.warn(\n"]},{"name":"stdout","output_type":"stream","text":["word (1-1)\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/sklearn/feature_extraction/text.py:521: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n","  warnings.warn(\n"]},{"name":"stdout","output_type":"stream","text":["word (1-1)\n","[['word (1-1)', 10, 50.45, 54.9, 46.67]]\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/sklearn/feature_extraction/text.py:521: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/feature_extraction/text.py:521: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n","  warnings.warn(\n"]},{"name":"stdout","output_type":"stream","text":["word (1-2)\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/feature_extraction/text.py:521: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n","  warnings.warn(\n"]},{"name":"stdout","output_type":"stream","text":["word (1-2)\n","word (1-2)\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/sklearn/feature_extraction/text.py:521: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n","  warnings.warn(\n"]},{"name":"stdout","output_type":"stream","text":["word (1-2)\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/sklearn/feature_extraction/text.py:521: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n","  warnings.warn(\n"]},{"name":"stdout","output_type":"stream","text":["word (1-2)\n","[['word (1-1)', 10, 50.45, 54.9, 46.67], ['word (1-2)', 1, 54.68, 66.87, 46.25]]\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/sklearn/feature_extraction/text.py:521: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/feature_extraction/text.py:521: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n","  warnings.warn(\n"]},{"name":"stdout","output_type":"stream","text":["word (1-3)\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/feature_extraction/text.py:521: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n","  warnings.warn(\n"]},{"name":"stdout","output_type":"stream","text":["word (1-3)\n","word (1-3)\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/sklearn/feature_extraction/text.py:521: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n","  warnings.warn(\n"]},{"name":"stdout","output_type":"stream","text":["word (1-3)\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/sklearn/feature_extraction/text.py:521: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n","  warnings.warn(\n"]},{"name":"stdout","output_type":"stream","text":["word (1-3)\n","[['word (1-1)', 10, 50.45, 54.9, 46.67], ['word (1-2)', 1, 54.68, 66.87, 46.25], ['word (1-3)', 10, 55.71, 61.62, 50.83]]\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/sklearn/feature_extraction/text.py:521: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/feature_extraction/text.py:521: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n","  warnings.warn(\n"]},{"name":"stdout","output_type":"stream","text":["word (1-4)\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/feature_extraction/text.py:521: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n","  warnings.warn(\n"]},{"name":"stdout","output_type":"stream","text":["word (1-4)\n","word (1-4)\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/sklearn/feature_extraction/text.py:521: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n","  warnings.warn(\n"]},{"name":"stdout","output_type":"stream","text":["word (1-4)\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/sklearn/feature_extraction/text.py:521: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n","  warnings.warn(\n"]},{"name":"stdout","output_type":"stream","text":["word (1-4)\n","[['word (1-1)', 10, 50.45, 54.9, 46.67], ['word (1-2)', 1, 54.68, 66.87, 46.25], ['word (1-3)', 10, 55.71, 61.62, 50.83], ['word (1-4)', 10, 54.63, 59.61, 50.42]]\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/sklearn/feature_extraction/text.py:521: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/feature_extraction/text.py:521: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n","  warnings.warn(\n"]},{"name":"stdout","output_type":"stream","text":["word (1-5)\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"]},{"name":"stdout","output_type":"stream","text":["word (1-5)\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/sklearn/feature_extraction/text.py:521: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n","  warnings.warn(\n"]},{"name":"stdout","output_type":"stream","text":["word (1-5)\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/sklearn/feature_extraction/text.py:521: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n","  warnings.warn(\n"]},{"name":"stdout","output_type":"stream","text":["word (1-5)\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/sklearn/feature_extraction/text.py:521: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n","  warnings.warn(\n"]},{"name":"stdout","output_type":"stream","text":["word (1-5)\n","[['word (1-1)', 10, 50.45, 54.9, 46.67], ['word (1-2)', 1, 54.68, 66.87, 46.25], ['word (1-3)', 10, 55.71, 61.62, 50.83], ['word (1-4)', 10, 54.63, 59.61, 50.42], ['word (1-5)', 10, 54.09, 59.5, 49.58]]\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/sklearn/feature_extraction/text.py:521: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/feature_extraction/text.py:521: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n","  warnings.warn(\n"]},{"name":"stdout","output_type":"stream","text":["word (2-2)\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/feature_extraction/text.py:521: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n","  warnings.warn(\n"]},{"name":"stdout","output_type":"stream","text":["word (2-2)\n","word (2-2)\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/sklearn/feature_extraction/text.py:521: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n","  warnings.warn(\n"]},{"name":"stdout","output_type":"stream","text":["word (2-2)\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/sklearn/feature_extraction/text.py:521: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n","  warnings.warn(\n"]},{"name":"stdout","output_type":"stream","text":["word (2-2)\n","[['word (1-1)', 10, 50.45, 54.9, 46.67], ['word (1-2)', 1, 54.68, 66.87, 46.25], ['word (1-3)', 10, 55.71, 61.62, 50.83], ['word (1-4)', 10, 54.63, 59.61, 50.42], ['word (1-5)', 10, 54.09, 59.5, 49.58], ['word (2-2)', 10, 42.59, 47.92, 38.33]]\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/sklearn/feature_extraction/text.py:521: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/feature_extraction/text.py:521: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n","  warnings.warn(\n"]},{"name":"stdout","output_type":"stream","text":["word (2-3)\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/feature_extraction/text.py:521: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n","  warnings.warn(\n"]},{"name":"stdout","output_type":"stream","text":["word (2-3)\n","word (2-3)\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/sklearn/feature_extraction/text.py:521: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n","  warnings.warn(\n"]},{"name":"stdout","output_type":"stream","text":["word (2-3)\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/sklearn/feature_extraction/text.py:521: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n","  warnings.warn(\n"]},{"name":"stdout","output_type":"stream","text":["word (2-3)\n","[['word (1-1)', 10, 50.45, 54.9, 46.67], ['word (1-2)', 1, 54.68, 66.87, 46.25], ['word (1-3)', 10, 55.71, 61.62, 50.83], ['word (1-4)', 10, 54.63, 59.61, 50.42], ['word (1-5)', 10, 54.09, 59.5, 49.58], ['word (2-2)', 10, 42.59, 47.92, 38.33], ['word (2-3)', 10, 41.36, 49.71, 35.42]]\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/sklearn/feature_extraction/text.py:521: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/feature_extraction/text.py:521: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n","  warnings.warn(\n"]},{"name":"stdout","output_type":"stream","text":["word (2-4)\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/feature_extraction/text.py:521: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n","  warnings.warn(\n"]},{"name":"stdout","output_type":"stream","text":["word (2-4)\n","word (2-4)\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/sklearn/feature_extraction/text.py:521: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n","  warnings.warn(\n"]},{"name":"stdout","output_type":"stream","text":["word (2-4)\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/sklearn/feature_extraction/text.py:521: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n","  warnings.warn(\n"]},{"name":"stdout","output_type":"stream","text":["word (2-4)\n","[['word (1-1)', 10, 50.45, 54.9, 46.67], ['word (1-2)', 1, 54.68, 66.87, 46.25], ['word (1-3)', 10, 55.71, 61.62, 50.83], ['word (1-4)', 10, 54.63, 59.61, 50.42], ['word (1-5)', 10, 54.09, 59.5, 49.58], ['word (2-2)', 10, 42.59, 47.92, 38.33], ['word (2-3)', 10, 41.36, 49.71, 35.42], ['word (2-4)', 10, 39.19, 50.33, 32.08]]\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/sklearn/feature_extraction/text.py:521: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/feature_extraction/text.py:521: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n","  warnings.warn(\n"]},{"name":"stdout","output_type":"stream","text":["word (2-5)\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/feature_extraction/text.py:521: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n","  warnings.warn(\n"]},{"name":"stdout","output_type":"stream","text":["word (2-5)\n","word (2-5)\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/sklearn/feature_extraction/text.py:521: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n","  warnings.warn(\n"]},{"name":"stdout","output_type":"stream","text":["word (2-5)\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/sklearn/feature_extraction/text.py:521: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n","  warnings.warn(\n"]},{"name":"stdout","output_type":"stream","text":["word (2-5)\n","[['word (1-1)', 10, 50.45, 54.9, 46.67], ['word (1-2)', 1, 54.68, 66.87, 46.25], ['word (1-3)', 10, 55.71, 61.62, 50.83], ['word (1-4)', 10, 54.63, 59.61, 50.42], ['word (1-5)', 10, 54.09, 59.5, 49.58], ['word (2-2)', 10, 42.59, 47.92, 38.33], ['word (2-3)', 10, 41.36, 49.71, 35.42], ['word (2-4)', 10, 39.19, 50.33, 32.08], ['word (2-5)', 10, 38.32, 51.77, 30.42]]\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/sklearn/feature_extraction/text.py:521: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/feature_extraction/text.py:521: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n","  warnings.warn(\n"]},{"name":"stdout","output_type":"stream","text":["word (3-3)\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/feature_extraction/text.py:521: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n","  warnings.warn(\n"]},{"name":"stdout","output_type":"stream","text":["word (3-3)\n","word (3-3)\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/sklearn/feature_extraction/text.py:521: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n","  warnings.warn(\n"]},{"name":"stdout","output_type":"stream","text":["word (3-3)\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/sklearn/feature_extraction/text.py:521: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n","  warnings.warn(\n"]},{"name":"stdout","output_type":"stream","text":["word (3-3)\n","[['word (1-1)', 10, 50.45, 54.9, 46.67], ['word (1-2)', 1, 54.68, 66.87, 46.25], ['word (1-3)', 10, 55.71, 61.62, 50.83], ['word (1-4)', 10, 54.63, 59.61, 50.42], ['word (1-5)', 10, 54.09, 59.5, 49.58], ['word (2-2)', 10, 42.59, 47.92, 38.33], ['word (2-3)', 10, 41.36, 49.71, 35.42], ['word (2-4)', 10, 39.19, 50.33, 32.08], ['word (2-5)', 10, 38.32, 51.77, 30.42], ['word (3-3)', 10, 25.21, 40.37, 18.33]]\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/sklearn/feature_extraction/text.py:521: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/feature_extraction/text.py:521: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n","  warnings.warn(\n"]},{"name":"stdout","output_type":"stream","text":["word (3-4)\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/feature_extraction/text.py:521: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n","  warnings.warn(\n"]},{"name":"stdout","output_type":"stream","text":["word (3-4)\n","word (3-4)\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/sklearn/feature_extraction/text.py:521: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n","  warnings.warn(\n"]},{"name":"stdout","output_type":"stream","text":["word (3-4)\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/sklearn/feature_extraction/text.py:521: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n","  warnings.warn(\n"]},{"name":"stdout","output_type":"stream","text":["word (3-4)\n","[['word (1-1)', 10, 50.45, 54.9, 46.67], ['word (1-2)', 1, 54.68, 66.87, 46.25], ['word (1-3)', 10, 55.71, 61.62, 50.83], ['word (1-4)', 10, 54.63, 59.61, 50.42], ['word (1-5)', 10, 54.09, 59.5, 49.58], ['word (2-2)', 10, 42.59, 47.92, 38.33], ['word (2-3)', 10, 41.36, 49.71, 35.42], ['word (2-4)', 10, 39.19, 50.33, 32.08], ['word (2-5)', 10, 38.32, 51.77, 30.42], ['word (3-3)', 10, 25.21, 40.37, 18.33], ['word (3-4)', 10, 22.49, 41.57, 15.42]]\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/sklearn/feature_extraction/text.py:521: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/feature_extraction/text.py:521: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n","  warnings.warn(\n"]},{"name":"stdout","output_type":"stream","text":["word (3-5)\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/feature_extraction/text.py:521: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n","  warnings.warn(\n"]},{"name":"stdout","output_type":"stream","text":["word (3-5)\n","word (3-5)\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/sklearn/feature_extraction/text.py:521: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n","  warnings.warn(\n"]},{"name":"stdout","output_type":"stream","text":["word (3-5)\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/sklearn/feature_extraction/text.py:521: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n","  warnings.warn(\n"]},{"name":"stdout","output_type":"stream","text":["word (3-5)\n","[['word (1-1)', 10, 50.45, 54.9, 46.67], ['word (1-2)', 1, 54.68, 66.87, 46.25], ['word (1-3)', 10, 55.71, 61.62, 50.83], ['word (1-4)', 10, 54.63, 59.61, 50.42], ['word (1-5)', 10, 54.09, 59.5, 49.58], ['word (2-2)', 10, 42.59, 47.92, 38.33], ['word (2-3)', 10, 41.36, 49.71, 35.42], ['word (2-4)', 10, 39.19, 50.33, 32.08], ['word (2-5)', 10, 38.32, 51.77, 30.42], ['word (3-3)', 10, 25.21, 40.37, 18.33], ['word (3-4)', 10, 22.49, 41.57, 15.42], ['word (3-5)', 10, 20.69, 41.77, 13.75]]\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/sklearn/feature_extraction/text.py:521: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/feature_extraction/text.py:521: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n","  warnings.warn(\n"]},{"name":"stdout","output_type":"stream","text":["word (4-4)\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/feature_extraction/text.py:521: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n","  warnings.warn(\n"]},{"name":"stdout","output_type":"stream","text":["word (4-4)\n","word (4-4)\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/sklearn/feature_extraction/text.py:521: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n","  warnings.warn(\n"]},{"name":"stdout","output_type":"stream","text":["word (4-4)\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/sklearn/feature_extraction/text.py:521: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n","  warnings.warn(\n"]},{"name":"stdout","output_type":"stream","text":["word (4-4)\n","[['word (1-1)', 10, 50.45, 54.9, 46.67], ['word (1-2)', 1, 54.68, 66.87, 46.25], ['word (1-3)', 10, 55.71, 61.62, 50.83], ['word (1-4)', 10, 54.63, 59.61, 50.42], ['word (1-5)', 10, 54.09, 59.5, 49.58], ['word (2-2)', 10, 42.59, 47.92, 38.33], ['word (2-3)', 10, 41.36, 49.71, 35.42], ['word (2-4)', 10, 39.19, 50.33, 32.08], ['word (2-5)', 10, 38.32, 51.77, 30.42], ['word (3-3)', 10, 25.21, 40.37, 18.33], ['word (3-4)', 10, 22.49, 41.57, 15.42], ['word (3-5)', 10, 20.69, 41.77, 13.75], ['word (4-4)', 10, 11.59, 44.44, 6.67]]\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/sklearn/feature_extraction/text.py:521: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/feature_extraction/text.py:521: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n","  warnings.warn(\n"]},{"name":"stdout","output_type":"stream","text":["word (4-5)\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/feature_extraction/text.py:521: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n","  warnings.warn(\n"]},{"name":"stdout","output_type":"stream","text":["word (4-5)\n","word (4-5)\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/sklearn/feature_extraction/text.py:521: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n","  warnings.warn(\n"]},{"name":"stdout","output_type":"stream","text":["word (4-5)\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/sklearn/feature_extraction/text.py:521: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n","  warnings.warn(\n"]},{"name":"stdout","output_type":"stream","text":["word (4-5)\n","[['word (1-1)', 10, 50.45, 54.9, 46.67], ['word (1-2)', 1, 54.68, 66.87, 46.25], ['word (1-3)', 10, 55.71, 61.62, 50.83], ['word (1-4)', 10, 54.63, 59.61, 50.42], ['word (1-5)', 10, 54.09, 59.5, 49.58], ['word (2-2)', 10, 42.59, 47.92, 38.33], ['word (2-3)', 10, 41.36, 49.71, 35.42], ['word (2-4)', 10, 39.19, 50.33, 32.08], ['word (2-5)', 10, 38.32, 51.77, 30.42], ['word (3-3)', 10, 25.21, 40.37, 18.33], ['word (3-4)', 10, 22.49, 41.57, 15.42], ['word (3-5)', 10, 20.69, 41.77, 13.75], ['word (4-4)', 10, 11.59, 44.44, 6.67], ['word (4-5)', 10, 11.11, 50.0, 6.25]]\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/sklearn/feature_extraction/text.py:521: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/feature_extraction/text.py:521: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n","  warnings.warn(\n"]},{"name":"stdout","output_type":"stream","text":["word (5-5)\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/feature_extraction/text.py:521: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n","  warnings.warn(\n"]},{"name":"stdout","output_type":"stream","text":["word (5-5)\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/feature_extraction/text.py:521: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n","  warnings.warn(\n"]},{"name":"stdout","output_type":"stream","text":["word (5-5)\n","word (5-5)\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/sklearn/feature_extraction/text.py:521: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n","  warnings.warn(\n"]},{"name":"stdout","output_type":"stream","text":["word (5-5)\n","[['word (1-1)', 10, 50.45, 54.9, 46.67], ['word (1-2)', 1, 54.68, 66.87, 46.25], ['word (1-3)', 10, 55.71, 61.62, 50.83], ['word (1-4)', 10, 54.63, 59.61, 50.42], ['word (1-5)', 10, 54.09, 59.5, 49.58], ['word (2-2)', 10, 42.59, 47.92, 38.33], ['word (2-3)', 10, 41.36, 49.71, 35.42], ['word (2-4)', 10, 39.19, 50.33, 32.08], ['word (2-5)', 10, 38.32, 51.77, 30.42], ['word (3-3)', 10, 25.21, 40.37, 18.33], ['word (3-4)', 10, 22.49, 41.57, 15.42], ['word (3-5)', 10, 20.69, 41.77, 13.75], ['word (4-4)', 10, 11.59, 44.44, 6.67], ['word (4-5)', 10, 11.11, 50.0, 6.25], ['word (5-5)', 10, 3.2, 40.0, 1.67]]\n"]}],"source":["def word_n_gram(train, test):\n","\n","  gram = \"word\"\n","  xs = [1, 2, 3, 4,5]\n","  ys = [1, 2, 3, 4, 5]\n","  word_svm_result_df = []\n","  for x1 in xs:\n","    for y1 in ys:\n","      if( x1 <= y1):\n","        Cs = [0.001, 0.001,0.1, 1, 10]\n","        ansF = 0\n","        ansP = 0\n","        ansR = 0\n","        ansC = 0\n","        model =  'word (' + str(x1) + '-' + str(y1) +')'\n","        temp = []\n","        for c in Cs:\n","\n","          f1_dic = dict()\n","\n","          scores = []\n","\n","\n","          trainData = train['Data']\n","          trainLabel = train['Label']\n","          testData = test['Data']\n","          testLabel = test['Label'].tolist()\n","\n","\n","\n","          # tfidf_vect_ngram = TfidfVectorizer(analyzer='char', ngram_range=(7,7), max_features=300000, max_df = 0.99)\n","          tfidf_vect_ngram = TfidfVectorizer(analyzer=gram, ngram_range=(x1,y1), tokenizer=lambda x: x.split())\n","\n","          tfidf_vect_ngram.fit(trainData)\n","          #feature_names = tfidf_vect_ngram.get_feature_names()\n","          xtrain =  tfidf_vect_ngram.transform(trainData)\n","          xtest =  tfidf_vect_ngram.transform(testData)\n","\n","\n","          linear = LinearSVC(C = c, penalty='l2', loss = 'squared_hinge') #squared_\n","\n","          linear.fit(xtrain, trainLabel)\n","\n","          pred_test = linear.predict(xtest)\n","\n","          pred_tem_test = pred_test.tolist()\n","\n","          f1 = round(f1_score( testLabel, pred_tem_test ) * 100 , 2)\n","          recall = round(recall_score( testLabel, pred_tem_test ) * 100 , 2)\n","          precision = round(precision_score( testLabel, pred_tem_test ) * 100 , 2)\n","\n","\n","\n","          print(model)\n","\n","\n","\n","          if(ansF < f1 ):\n","            ansC = c\n","            ansF = f1\n","            ansP = precision\n","            ansR = recall\n","\n","        temp.append(model)\n","        temp.append(ansC)\n","        temp.append(ansF)\n","        temp.append(ansP)\n","        temp.append(ansR)\n","        word_svm_result_df.append(temp)\n","\n","        print(word_svm_result_df)\n","\n","  return word_svm_result_df\n","\n","\n","\n","if __name__ == '__main__':\n","\n","  # path_parent = os.path.dirname( os.getcwd() )\n","  # os.chdir( path_parent )\n","  df_train = pd.read_csv( \"/content/drive/MyDrive/1a/Learning From Data/Final Project/data/train.tsv\", sep=\"\\t\", names = ['Data', 'Label'] )\n","  df_val =  pd.read_csv( \"/content/drive/MyDrive/1a/Learning From Data/Final Project/data/dev.tsv\", sep=\"\\t\", names = ['Data', 'Label'] )\n","  df_test = pd.read_csv( \"/content/drive/MyDrive/1a/Learning From Data/Final Project/data/test.tsv\", sep=\"\\t\", names = ['Data', 'Label'] )\n","\n","  for df in [df_train, df_val, df_test]:\n","    df['Label'] = df['Label'].apply(lambda x: 0 if x == \"NOT\" else 1 )\n","\n","  word_svm_df = word_n_gram(df_train, df_test)\n","  word_svm = pd.DataFrame( word_svm_df, columns = [\"Model Name\", \"C Value\", \"F-1 (Binary) Macro score\", \"Precision\", \"Recall\"] )\n","  word_svm.to_csv('/content/drive/MyDrive/1a/Learning From Data/Final Project/results/Word_SVM.csv', index = False)\n"]},{"cell_type":"markdown","metadata":{"id":"S60sDybeGHk9"},"source":["# Char N-Gram *Tuning*"]},{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":0},"id":"29Kb27ncFLZk","executionInfo":{"status":"error","timestamp":1730198882297,"user_tz":-60,"elapsed":785,"user":{"displayName":"K.I. Islam","userId":"09685597978258818855"}},"outputId":"92ef8008-b0b5-496d-a9ca-cb95e0c8ea0f"},"outputs":[{"output_type":"error","ename":"NameError","evalue":"name 'pd' is not defined","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-1-d8d597487d45>\u001b[0m in \u001b[0;36m<cell line: 77>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     79\u001b[0m   \u001b[0;31m# path_parent = os.path.dirname( os.getcwd() )\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m   \u001b[0;31m# os.chdir( path_parent )\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 81\u001b[0;31m   \u001b[0mdf_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0;34m\"/content/drive/MyDrive/1a/Learning From Data/Final Project/data/train.tsv\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msep\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"\\t\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnames\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'Data'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Label'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     82\u001b[0m   \u001b[0mdf_val\u001b[0m \u001b[0;34m=\u001b[0m  \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0;34m\"/content/drive/MyDrive/1a/Learning From Data/Final Project/data/dev.tsv\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msep\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"\\t\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnames\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'Data'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Label'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     83\u001b[0m   \u001b[0mdf_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0;34m\"/content/drive/MyDrive/1a/Learning From Data/Final Project/data/test.tsv\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msep\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"\\t\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnames\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'Data'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Label'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: name 'pd' is not defined"]}],"source":["def char_n_gram(train, test):\n","\n","  gram = \"char\"\n","  xs = [1, 2, 3, 4,5]\n","  ys = [1, 2, 3, 4, 5]\n","  char_svm_result_df = []\n","  for x1 in xs:\n","    for y1 in ys:\n","      if( x1 <= y1):\n","        Cs = [0.001, 0.001,0.1, 1, 10]\n","        ansF = 0\n","        ansP = 0\n","        ansR = 0\n","        ansC = 0\n","        model =  'char (' + str(x1) + '-' + str(y1) +')'\n","        temp = []\n","        for c in Cs:\n","\n","          f1_dic = dict()\n","\n","          scores = []\n","\n","\n","          trainData = train['Data']\n","          trainLabel = train['Label']\n","          testData = test['Data']\n","          testLabel = test['Label'].tolist()\n","\n","\n","\n","          # tfidf_vect_ngram = TfidfVectorizer(analyzer='char', ngram_range=(7,7), max_features=300000, max_df = 0.99)\n","          tfidf_vect_ngram = TfidfVectorizer(analyzer=gram, ngram_range=(x1,y1), tokenizer=lambda x: x.split())\n","\n","          tfidf_vect_ngram.fit(trainData)\n","          #feature_names = tfidf_vect_ngram.get_feature_names()\n","          xtrain =  tfidf_vect_ngram.transform(trainData)\n","          xtest =  tfidf_vect_ngram.transform(testData)\n","\n","\n","          linear = LinearSVC(C = c, penalty='l2', loss = 'squared_hinge') #squared_\n","\n","          linear.fit(xtrain, trainLabel)\n","\n","          pred_test = linear.predict(xtest)\n","\n","          pred_tem_test = pred_test.tolist()\n","\n","          f1 = round(f1_score( testLabel, pred_tem_test ) * 100 , 2)\n","          recall = round(recall_score( testLabel, pred_tem_test ) * 100 , 2)\n","          precision = round(precision_score( testLabel, pred_tem_test ) * 100 , 2)\n","\n","\n","\n","          print(model)\n","\n","\n","\n","          if(ansF < f1 ):\n","            ansC = c\n","            ansF = f1\n","            ansP = precision\n","            ansR = recall\n","\n","        temp.append(model)\n","        temp.append(ansC)\n","        temp.append(ansF)\n","        temp.append(ansP)\n","        temp.append(ansR)\n","        char_svm_result_df.append(temp)\n","\n","        print(char_svm_result_df)\n","\n","  return char_svm_result_df\n","\n","\n","\n","if __name__ == '__main__':\n","\n","  # path_parent = os.path.dirname( os.getcwd() )\n","  # os.chdir( path_parent )\n","  df_train = pd.read_csv( \"/content/drive/MyDrive/1a/Learning From Data/Final Project/data/train.tsv\", sep=\"\\t\", names = ['Data', 'Label'] )\n","  df_val =  pd.read_csv( \"/content/drive/MyDrive/1a/Learning From Data/Final Project/data/dev.tsv\", sep=\"\\t\", names = ['Data', 'Label'] )\n","  df_test = pd.read_csv( \"/content/drive/MyDrive/1a/Learning From Data/Final Project/data/test.tsv\", sep=\"\\t\", names = ['Data', 'Label'] )\n","\n","  for df in [df_train, df_val, df_test]:\n","    df['Label'] = df['Label'].apply(lambda x: 0 if x == \"NOT\" else 1 )\n","\n","  char_svm_df = char_n_gram(df_train, df_test)\n","  char_svm = pd.DataFrame( char_svm_df, columns = [\"Model Name\", \"C Value\", \"F-1 (Binary) Macro score\", \"Precision\", \"Recall\"] )\n","  char_svm.to_csv('/content/drive/MyDrive/1a/Learning From Data/Final Project/results/Char_SVM.csv', index = False)\n"]},{"cell_type":"markdown","metadata":{"id":"KWbwlCckHXUd"},"source":["# Word And Char *Tuning*"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":745093,"status":"ok","timestamp":1729852174642,"user":{"displayName":"K.I. Islam","userId":"09685597978258818855"},"user_tz":-120},"id":"-WunVoi6HNdP","outputId":"b89879c3-ff44-4f54-cd4f-ce61761962bc"},"outputs":[{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/sklearn/feature_extraction/text.py:521: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/sklearn/feature_extraction/text.py:556: UserWarning: The parameter 'tokenizer' will not be used since 'analyzer' != 'word'\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/feature_extraction/text.py:521: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n","  warnings.warn(\n"]},{"name":"stdout","output_type":"stream","text":["word (1-1) char (1-1)\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/sklearn/feature_extraction/text.py:556: UserWarning: The parameter 'tokenizer' will not be used since 'analyzer' != 'word'\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/feature_extraction/text.py:521: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n","  warnings.warn(\n"]},{"name":"stdout","output_type":"stream","text":["word (1-1) char (1-1)\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/sklearn/feature_extraction/text.py:556: UserWarning: The parameter 'tokenizer' will not be used since 'analyzer' != 'word'\n","  warnings.warn(\n"]},{"name":"stdout","output_type":"stream","text":["word (1-1) char (1-1)\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/sklearn/feature_extraction/text.py:521: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/sklearn/feature_extraction/text.py:556: UserWarning: The parameter 'tokenizer' will not be used since 'analyzer' != 'word'\n","  warnings.warn(\n"]},{"name":"stdout","output_type":"stream","text":["word (1-1) char (1-1)\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/sklearn/feature_extraction/text.py:521: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/sklearn/feature_extraction/text.py:556: UserWarning: The parameter 'tokenizer' will not be used since 'analyzer' != 'word'\n","  warnings.warn(\n"]},{"name":"stdout","output_type":"stream","text":["word (1-1) char (1-1)\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/sklearn/feature_extraction/text.py:521: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/sklearn/feature_extraction/text.py:556: UserWarning: The parameter 'tokenizer' will not be used since 'analyzer' != 'word'\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/feature_extraction/text.py:521: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n","  warnings.warn(\n"]},{"name":"stdout","output_type":"stream","text":["word (1-1) char (1-2)\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/sklearn/feature_extraction/text.py:556: UserWarning: The parameter 'tokenizer' will not be used since 'analyzer' != 'word'\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/feature_extraction/text.py:521: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n","  warnings.warn(\n"]},{"name":"stdout","output_type":"stream","text":["word (1-1) char (1-2)\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/sklearn/feature_extraction/text.py:556: UserWarning: The parameter 'tokenizer' will not be used since 'analyzer' != 'word'\n","  warnings.warn(\n"]},{"name":"stdout","output_type":"stream","text":["word (1-1) char (1-2)\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/sklearn/feature_extraction/text.py:521: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/sklearn/feature_extraction/text.py:556: UserWarning: The parameter 'tokenizer' will not be used since 'analyzer' != 'word'\n","  warnings.warn(\n"]},{"name":"stdout","output_type":"stream","text":["word (1-1) char (1-2)\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/sklearn/feature_extraction/text.py:521: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/sklearn/feature_extraction/text.py:556: UserWarning: The parameter 'tokenizer' will not be used since 'analyzer' != 'word'\n","  warnings.warn(\n"]},{"name":"stdout","output_type":"stream","text":["word (1-1) char (1-2)\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/sklearn/feature_extraction/text.py:521: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/sklearn/feature_extraction/text.py:556: UserWarning: The parameter 'tokenizer' will not be used since 'analyzer' != 'word'\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/feature_extraction/text.py:521: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n","  warnings.warn(\n"]},{"name":"stdout","output_type":"stream","text":["word (1-1) char (1-3)\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/sklearn/feature_extraction/text.py:556: UserWarning: The parameter 'tokenizer' will not be used since 'analyzer' != 'word'\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/feature_extraction/text.py:521: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n","  warnings.warn(\n"]},{"name":"stdout","output_type":"stream","text":["word (1-1) char (1-3)\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/sklearn/feature_extraction/text.py:556: UserWarning: The parameter 'tokenizer' will not be used since 'analyzer' != 'word'\n","  warnings.warn(\n"]},{"name":"stdout","output_type":"stream","text":["word (1-1) char (1-3)\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/sklearn/feature_extraction/text.py:521: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/sklearn/feature_extraction/text.py:556: UserWarning: The parameter 'tokenizer' will not be used since 'analyzer' != 'word'\n","  warnings.warn(\n"]},{"name":"stdout","output_type":"stream","text":["word (1-1) char (1-3)\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/sklearn/feature_extraction/text.py:521: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/sklearn/feature_extraction/text.py:556: UserWarning: The parameter 'tokenizer' will not be used since 'analyzer' != 'word'\n","  warnings.warn(\n"]},{"name":"stdout","output_type":"stream","text":["word (1-1) char (1-3)\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/sklearn/feature_extraction/text.py:521: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/sklearn/feature_extraction/text.py:556: UserWarning: The parameter 'tokenizer' will not be used since 'analyzer' != 'word'\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/feature_extraction/text.py:521: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n","  warnings.warn(\n"]},{"name":"stdout","output_type":"stream","text":["word (1-1) char (1-4)\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/sklearn/feature_extraction/text.py:556: UserWarning: The parameter 'tokenizer' will not be used since 'analyzer' != 'word'\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/feature_extraction/text.py:521: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n","  warnings.warn(\n"]},{"name":"stdout","output_type":"stream","text":["word (1-1) char (1-4)\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/sklearn/feature_extraction/text.py:556: UserWarning: The parameter 'tokenizer' will not be used since 'analyzer' != 'word'\n","  warnings.warn(\n"]},{"name":"stdout","output_type":"stream","text":["word (1-1) char (1-4)\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/sklearn/feature_extraction/text.py:521: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/sklearn/feature_extraction/text.py:556: UserWarning: The parameter 'tokenizer' will not be used since 'analyzer' != 'word'\n","  warnings.warn(\n"]},{"name":"stdout","output_type":"stream","text":["word (1-1) char (1-4)\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/sklearn/feature_extraction/text.py:521: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/sklearn/feature_extraction/text.py:556: UserWarning: The parameter 'tokenizer' will not be used since 'analyzer' != 'word'\n","  warnings.warn(\n"]},{"name":"stdout","output_type":"stream","text":["word (1-1) char (1-4)\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/sklearn/feature_extraction/text.py:521: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/sklearn/feature_extraction/text.py:556: UserWarning: The parameter 'tokenizer' will not be used since 'analyzer' != 'word'\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/feature_extraction/text.py:521: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n","  warnings.warn(\n"]},{"name":"stdout","output_type":"stream","text":["word (1-1) char (1-5)\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/sklearn/feature_extraction/text.py:556: UserWarning: The parameter 'tokenizer' will not be used since 'analyzer' != 'word'\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/feature_extraction/text.py:521: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n","  warnings.warn(\n"]},{"name":"stdout","output_type":"stream","text":["word (1-1) char (1-5)\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/sklearn/feature_extraction/text.py:556: UserWarning: The parameter 'tokenizer' will not be used since 'analyzer' != 'word'\n","  warnings.warn(\n"]},{"name":"stdout","output_type":"stream","text":["word (1-1) char (1-5)\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/sklearn/feature_extraction/text.py:521: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/sklearn/feature_extraction/text.py:556: UserWarning: The parameter 'tokenizer' will not be used since 'analyzer' != 'word'\n","  warnings.warn(\n"]},{"name":"stdout","output_type":"stream","text":["word (1-1) char (1-5)\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/sklearn/feature_extraction/text.py:521: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/sklearn/feature_extraction/text.py:556: UserWarning: The parameter 'tokenizer' will not be used since 'analyzer' != 'word'\n","  warnings.warn(\n"]},{"name":"stdout","output_type":"stream","text":["word (1-1) char (1-5)\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/sklearn/feature_extraction/text.py:521: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/sklearn/feature_extraction/text.py:556: UserWarning: The parameter 'tokenizer' will not be used since 'analyzer' != 'word'\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/feature_extraction/text.py:521: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n","  warnings.warn(\n"]},{"name":"stdout","output_type":"stream","text":["word (1-1) char (2-2)\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/sklearn/feature_extraction/text.py:556: UserWarning: The parameter 'tokenizer' will not be used since 'analyzer' != 'word'\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/feature_extraction/text.py:521: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n","  warnings.warn(\n"]},{"name":"stdout","output_type":"stream","text":["word (1-1) char (2-2)\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/sklearn/feature_extraction/text.py:556: UserWarning: The parameter 'tokenizer' will not be used since 'analyzer' != 'word'\n","  warnings.warn(\n"]},{"name":"stdout","output_type":"stream","text":["word (1-1) char (2-2)\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/sklearn/feature_extraction/text.py:521: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/sklearn/feature_extraction/text.py:556: UserWarning: The parameter 'tokenizer' will not be used since 'analyzer' != 'word'\n","  warnings.warn(\n"]},{"name":"stdout","output_type":"stream","text":["word (1-1) char (2-2)\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/sklearn/feature_extraction/text.py:521: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/sklearn/feature_extraction/text.py:556: UserWarning: The parameter 'tokenizer' will not be used since 'analyzer' != 'word'\n","  warnings.warn(\n"]},{"name":"stdout","output_type":"stream","text":["word (1-1) char (2-2)\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/sklearn/feature_extraction/text.py:521: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/sklearn/feature_extraction/text.py:556: UserWarning: The parameter 'tokenizer' will not be used since 'analyzer' != 'word'\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/feature_extraction/text.py:521: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n","  warnings.warn(\n"]},{"name":"stdout","output_type":"stream","text":["word (1-1) char (2-3)\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/sklearn/feature_extraction/text.py:556: UserWarning: The parameter 'tokenizer' will not be used since 'analyzer' != 'word'\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/feature_extraction/text.py:521: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n","  warnings.warn(\n"]},{"name":"stdout","output_type":"stream","text":["word (1-1) char (2-3)\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/sklearn/feature_extraction/text.py:556: UserWarning: The parameter 'tokenizer' will not be used since 'analyzer' != 'word'\n","  warnings.warn(\n"]},{"name":"stdout","output_type":"stream","text":["word (1-1) char (2-3)\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/sklearn/feature_extraction/text.py:521: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/sklearn/feature_extraction/text.py:556: UserWarning: The parameter 'tokenizer' will not be used since 'analyzer' != 'word'\n","  warnings.warn(\n"]},{"name":"stdout","output_type":"stream","text":["word (1-1) char (2-3)\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/sklearn/feature_extraction/text.py:521: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/sklearn/feature_extraction/text.py:556: UserWarning: The parameter 'tokenizer' will not be used since 'analyzer' != 'word'\n","  warnings.warn(\n"]},{"name":"stdout","output_type":"stream","text":["word (1-1) char (2-3)\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/sklearn/feature_extraction/text.py:521: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/sklearn/feature_extraction/text.py:556: UserWarning: The parameter 'tokenizer' will not be used since 'analyzer' != 'word'\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/feature_extraction/text.py:521: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n","  warnings.warn(\n"]},{"name":"stdout","output_type":"stream","text":["word (1-1) char (2-4)\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/sklearn/feature_extraction/text.py:556: UserWarning: The parameter 'tokenizer' will not be used since 'analyzer' != 'word'\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/feature_extraction/text.py:521: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n","  warnings.warn(\n"]},{"name":"stdout","output_type":"stream","text":["word (1-1) char (2-4)\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/sklearn/feature_extraction/text.py:556: UserWarning: The parameter 'tokenizer' will not be used since 'analyzer' != 'word'\n","  warnings.warn(\n"]},{"name":"stdout","output_type":"stream","text":["word (1-1) char (2-4)\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/sklearn/feature_extraction/text.py:521: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/sklearn/feature_extraction/text.py:556: UserWarning: The parameter 'tokenizer' will not be used since 'analyzer' != 'word'\n","  warnings.warn(\n"]},{"name":"stdout","output_type":"stream","text":["word (1-1) char (2-4)\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/sklearn/feature_extraction/text.py:521: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/sklearn/feature_extraction/text.py:556: UserWarning: The parameter 'tokenizer' will not be used since 'analyzer' != 'word'\n","  warnings.warn(\n"]},{"name":"stdout","output_type":"stream","text":["word (1-1) char (2-4)\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/sklearn/feature_extraction/text.py:521: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/sklearn/feature_extraction/text.py:556: UserWarning: The parameter 'tokenizer' will not be used since 'analyzer' != 'word'\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/feature_extraction/text.py:521: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n","  warnings.warn(\n"]},{"name":"stdout","output_type":"stream","text":["word (1-1) char (2-5)\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/sklearn/feature_extraction/text.py:556: UserWarning: The parameter 'tokenizer' will not be used since 'analyzer' != 'word'\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/feature_extraction/text.py:521: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n","  warnings.warn(\n"]},{"name":"stdout","output_type":"stream","text":["word (1-1) char (2-5)\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/sklearn/feature_extraction/text.py:556: UserWarning: The parameter 'tokenizer' will not be used since 'analyzer' != 'word'\n","  warnings.warn(\n"]},{"name":"stdout","output_type":"stream","text":["word (1-1) char (2-5)\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/sklearn/feature_extraction/text.py:521: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/sklearn/feature_extraction/text.py:556: UserWarning: The parameter 'tokenizer' will not be used since 'analyzer' != 'word'\n","  warnings.warn(\n"]},{"name":"stdout","output_type":"stream","text":["word (1-1) char (2-5)\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/sklearn/feature_extraction/text.py:521: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/sklearn/feature_extraction/text.py:556: UserWarning: The parameter 'tokenizer' will not be used since 'analyzer' != 'word'\n","  warnings.warn(\n"]},{"name":"stdout","output_type":"stream","text":["word (1-1) char (2-5)\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/sklearn/feature_extraction/text.py:521: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/sklearn/feature_extraction/text.py:556: UserWarning: The parameter 'tokenizer' will not be used since 'analyzer' != 'word'\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/feature_extraction/text.py:521: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n","  warnings.warn(\n"]},{"name":"stdout","output_type":"stream","text":["word (1-1) char (3-3)\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/sklearn/feature_extraction/text.py:556: UserWarning: The parameter 'tokenizer' will not be used since 'analyzer' != 'word'\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/feature_extraction/text.py:521: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n","  warnings.warn(\n"]},{"name":"stdout","output_type":"stream","text":["word (1-1) char (3-3)\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/sklearn/feature_extraction/text.py:556: UserWarning: The parameter 'tokenizer' will not be used since 'analyzer' != 'word'\n","  warnings.warn(\n"]},{"name":"stdout","output_type":"stream","text":["word (1-1) char (3-3)\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/sklearn/feature_extraction/text.py:521: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/sklearn/feature_extraction/text.py:556: UserWarning: The parameter 'tokenizer' will not be used since 'analyzer' != 'word'\n","  warnings.warn(\n"]},{"name":"stdout","output_type":"stream","text":["word (1-1) char (3-3)\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/sklearn/feature_extraction/text.py:521: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/sklearn/feature_extraction/text.py:556: UserWarning: The parameter 'tokenizer' will not be used since 'analyzer' != 'word'\n","  warnings.warn(\n"]},{"name":"stdout","output_type":"stream","text":["word (1-1) char (3-3)\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/sklearn/feature_extraction/text.py:521: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/sklearn/feature_extraction/text.py:556: UserWarning: The parameter 'tokenizer' will not be used since 'analyzer' != 'word'\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/feature_extraction/text.py:521: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n","  warnings.warn(\n"]},{"name":"stdout","output_type":"stream","text":["word (1-1) char (3-4)\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/sklearn/feature_extraction/text.py:556: UserWarning: The parameter 'tokenizer' will not be used since 'analyzer' != 'word'\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/feature_extraction/text.py:521: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n","  warnings.warn(\n"]},{"name":"stdout","output_type":"stream","text":["word (1-1) char (3-4)\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/sklearn/feature_extraction/text.py:556: UserWarning: The parameter 'tokenizer' will not be used since 'analyzer' != 'word'\n","  warnings.warn(\n"]},{"name":"stdout","output_type":"stream","text":["word (1-1) char (3-4)\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/sklearn/feature_extraction/text.py:521: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/sklearn/feature_extraction/text.py:556: UserWarning: The parameter 'tokenizer' will not be used since 'analyzer' != 'word'\n","  warnings.warn(\n"]},{"name":"stdout","output_type":"stream","text":["word (1-1) char (3-4)\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/sklearn/feature_extraction/text.py:521: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/sklearn/feature_extraction/text.py:556: UserWarning: The parameter 'tokenizer' will not be used since 'analyzer' != 'word'\n","  warnings.warn(\n"]},{"name":"stdout","output_type":"stream","text":["word (1-1) char (3-4)\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/sklearn/feature_extraction/text.py:521: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/sklearn/feature_extraction/text.py:556: UserWarning: The parameter 'tokenizer' will not be used since 'analyzer' != 'word'\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/feature_extraction/text.py:521: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n","  warnings.warn(\n"]},{"name":"stdout","output_type":"stream","text":["word (1-1) char (3-5)\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/sklearn/feature_extraction/text.py:556: UserWarning: The parameter 'tokenizer' will not be used since 'analyzer' != 'word'\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/feature_extraction/text.py:521: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n","  warnings.warn(\n"]},{"name":"stdout","output_type":"stream","text":["word (1-1) char (3-5)\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/sklearn/feature_extraction/text.py:556: UserWarning: The parameter 'tokenizer' will not be used since 'analyzer' != 'word'\n","  warnings.warn(\n"]},{"name":"stdout","output_type":"stream","text":["word (1-1) char (3-5)\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/sklearn/feature_extraction/text.py:521: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/sklearn/feature_extraction/text.py:556: UserWarning: The parameter 'tokenizer' will not be used since 'analyzer' != 'word'\n","  warnings.warn(\n"]},{"name":"stdout","output_type":"stream","text":["word (1-1) char (3-5)\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/sklearn/feature_extraction/text.py:521: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/sklearn/feature_extraction/text.py:556: UserWarning: The parameter 'tokenizer' will not be used since 'analyzer' != 'word'\n","  warnings.warn(\n"]},{"name":"stdout","output_type":"stream","text":["word (1-1) char (3-5)\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/sklearn/feature_extraction/text.py:521: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/sklearn/feature_extraction/text.py:556: UserWarning: The parameter 'tokenizer' will not be used since 'analyzer' != 'word'\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/feature_extraction/text.py:521: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n","  warnings.warn(\n"]},{"name":"stdout","output_type":"stream","text":["word (1-1) char (4-4)\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/sklearn/feature_extraction/text.py:556: UserWarning: The parameter 'tokenizer' will not be used since 'analyzer' != 'word'\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/feature_extraction/text.py:521: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n","  warnings.warn(\n"]},{"name":"stdout","output_type":"stream","text":["word (1-1) char (4-4)\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/sklearn/feature_extraction/text.py:556: UserWarning: The parameter 'tokenizer' will not be used since 'analyzer' != 'word'\n","  warnings.warn(\n"]},{"name":"stdout","output_type":"stream","text":["word (1-1) char (4-4)\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/sklearn/feature_extraction/text.py:521: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/sklearn/feature_extraction/text.py:556: UserWarning: The parameter 'tokenizer' will not be used since 'analyzer' != 'word'\n","  warnings.warn(\n"]},{"name":"stdout","output_type":"stream","text":["word (1-1) char (4-4)\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/sklearn/feature_extraction/text.py:521: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/sklearn/feature_extraction/text.py:556: UserWarning: The parameter 'tokenizer' will not be used since 'analyzer' != 'word'\n","  warnings.warn(\n"]},{"name":"stdout","output_type":"stream","text":["word (1-1) char (4-4)\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/sklearn/feature_extraction/text.py:521: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/sklearn/feature_extraction/text.py:556: UserWarning: The parameter 'tokenizer' will not be used since 'analyzer' != 'word'\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/feature_extraction/text.py:521: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n","  warnings.warn(\n"]},{"name":"stdout","output_type":"stream","text":["word (1-1) char (4-5)\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/sklearn/feature_extraction/text.py:556: UserWarning: The parameter 'tokenizer' will not be used since 'analyzer' != 'word'\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/feature_extraction/text.py:521: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n","  warnings.warn(\n"]},{"name":"stdout","output_type":"stream","text":["word (1-1) char (4-5)\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/sklearn/feature_extraction/text.py:556: UserWarning: The parameter 'tokenizer' will not be used since 'analyzer' != 'word'\n","  warnings.warn(\n"]},{"name":"stdout","output_type":"stream","text":["word (1-1) char (4-5)\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/sklearn/feature_extraction/text.py:521: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/sklearn/feature_extraction/text.py:556: UserWarning: The parameter 'tokenizer' will not be used since 'analyzer' != 'word'\n","  warnings.warn(\n"]},{"name":"stdout","output_type":"stream","text":["word (1-1) char (4-5)\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/sklearn/feature_extraction/text.py:521: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/sklearn/feature_extraction/text.py:556: UserWarning: The parameter 'tokenizer' will not be used since 'analyzer' != 'word'\n","  warnings.warn(\n"]},{"name":"stdout","output_type":"stream","text":["word (1-1) char (4-5)\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/sklearn/feature_extraction/text.py:521: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/sklearn/feature_extraction/text.py:556: UserWarning: The parameter 'tokenizer' will not be used since 'analyzer' != 'word'\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/feature_extraction/text.py:521: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n","  warnings.warn(\n"]},{"name":"stdout","output_type":"stream","text":["word (1-1) char (5-5)\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/sklearn/feature_extraction/text.py:556: UserWarning: The parameter 'tokenizer' will not be used since 'analyzer' != 'word'\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/feature_extraction/text.py:521: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n","  warnings.warn(\n"]},{"name":"stdout","output_type":"stream","text":["word (1-1) char (5-5)\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/sklearn/feature_extraction/text.py:556: UserWarning: The parameter 'tokenizer' will not be used since 'analyzer' != 'word'\n","  warnings.warn(\n"]},{"name":"stdout","output_type":"stream","text":["word (1-1) char (5-5)\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/sklearn/feature_extraction/text.py:521: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/sklearn/feature_extraction/text.py:556: UserWarning: The parameter 'tokenizer' will not be used since 'analyzer' != 'word'\n","  warnings.warn(\n"]},{"name":"stdout","output_type":"stream","text":["word (1-1) char (5-5)\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/sklearn/feature_extraction/text.py:521: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/sklearn/feature_extraction/text.py:556: UserWarning: The parameter 'tokenizer' will not be used since 'analyzer' != 'word'\n","  warnings.warn(\n"]},{"name":"stdout","output_type":"stream","text":["word (1-1) char (5-5)\n"]}],"source":["def combo_word_char_n_gram(train, test):\n","  xs = [1]\n","  ys = [1]\n","  xs_char = [1, 2, 3, 4, 5]\n","  ys_char = [1, 2, 3, 4, 5 ]\n","  for x1 in xs:\n","    for y1 in ys:\n","      if( x1 <= y1 ):\n","        for x2 in xs_char:\n","          for y2 in ys_char:\n","            if( x2 <= y2 ):\n","\n","              model =  'word (' + str(x1) + '-' + str(y1) + ') char (' + str(x2) + '-' + str(y2) +')'\n","              temp = []\n","              upper = []\n","              precisionLower = []\n","              recallLower = []\n","              Cs = [0.001, 0.001,0.1, 1, 10]\n","              ansF = 0\n","              ansP = 0\n","              ansR = 0\n","              ansC = 0\n","\n","              df = pd.read_csv('/content/drive/MyDrive/1a/Learning From Data/Final Project/results/W_c_COMBO_SVM.csv')\n","              fin = df.values.tolist()\n","\n","              for c in Cs:\n","                scores = []\n","\n","\n","                trainData = train['Data']\n","                trainLabel = train['Label']\n","                testData = test['Data']\n","                testLabel = test['Label'].tolist()\n","\n","\n","\n","                # tfidf_vect_ngram = TfidfVectorizer(analyzer='char', ngram_range=(7,7), max_features=300000, max_df = 0.99)\n","                word_tfidf_vect_ngram = TfidfVectorizer(analyzer=\"word\", ngram_range=(x1,y1), tokenizer=lambda x: x.split())\n","\n","                word_tfidf_vect_ngram.fit(trainData)\n","                #feature_names_words = word_tfidf_vect_ngram.get_feature_names()\n","                xtrain_words = word_tfidf_vect_ngram.transform(trainData)\n","                xtest_words = word_tfidf_vect_ngram.transform(testData)\n","\n","\n","\n","                char_tfidf_vect_ngram = TfidfVectorizer(analyzer=\"char\", ngram_range=(x2,y2), tokenizer=lambda x: x.split())\n","\n","                char_tfidf_vect_ngram.fit(trainData)\n","                #feature_names_char = char_tfidf_vect_ngram.get_feature_names()\n","                xtrain_char = char_tfidf_vect_ngram.transform(trainData)\n","                xtest_char = char_tfidf_vect_ngram.transform(testData)\n","\n","                tfidf_matrix_word_char_train =  hstack((xtrain_words, xtrain_char))\n","                tfidf_matrix_word_char_test =  hstack((xtest_words, xtest_char))\n","\n","\n","                linear = LinearSVC(C = c, penalty='l2', loss = 'squared_hinge') #squared_\n","\n","                linear.fit(tfidf_matrix_word_char_train, trainLabel)\n","\n","                pred = linear.predict(tfidf_matrix_word_char_test)\n","\n","                f1 = round(f1_score( testLabel, pred ) * 100 , 2)\n","                recall = round(recall_score( testLabel, pred ) * 100 , 2)\n","                precision = round(precision_score( testLabel, pred ) * 100 , 2)\n","\n","\n","\n","                print(model)\n","\n","\n","\n","                if(ansF < f1 ):\n","                  ansC = c\n","                  ansF = f1\n","                  ansP = precision\n","                  ansR = recall\n","\n","              temp.append(model)\n","              temp.append(ansC)\n","              temp.append(ansF)\n","              temp.append(ansP)\n","              temp.append(ansR)\n","              fin.append(temp)\n","              char_svm = pd.DataFrame( fin, columns = [\"Model Name\", \"C Value\", \"F-1 (Binary) Macro score\", \"Precision\", \"Recall\"] )\n","              char_svm.to_csv('/content/drive/MyDrive/1a/Learning From Data/Final Project/results/W_c_COMBO_SVM.csv', index = False)\n","\n","\n","\n","if __name__ == '__main__':\n","\n","  # path_parent = os.path.dirname( os.getcwd() )\n","  # os.chdir( path_parent )\n","  df_train = pd.read_csv( \"/content/drive/MyDrive/1a/Learning From Data/Final Project/data/train.tsv\", sep=\"\\t\", names = ['Data', 'Label'] )\n","  df_val =  pd.read_csv( \"/content/drive/MyDrive/1a/Learning From Data/Final Project/data/dev.tsv\", sep=\"\\t\", names = ['Data', 'Label'] )\n","  df_test = pd.read_csv( \"/content/drive/MyDrive/1a/Learning From Data/Final Project/data/test.tsv\", sep=\"\\t\", names = ['Data', 'Label'] )\n","\n","  for df in [df_train, df_val, df_test]:\n","    df['Label'] = df['Label'].apply(lambda x: 0 if x == \"NOT\" else 1 )\n","\n","  combo_word_char_n_gram(df_train, df_test)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"_2bYFBQjJhXl"},"outputs":[],"source":[]}],"metadata":{"colab":{"toc_visible":true,"provenance":[],"mount_file_id":"1EASol4yaB1KQ5DtxyroSaoILk_Ke94oa","authorship_tag":"ABX9TyOYTO7BRCYH+/oAKF1KLuEo"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}